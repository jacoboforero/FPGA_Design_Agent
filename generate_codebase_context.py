#!/usr/bin/env python3
"""
Generate Codebase Context for Gemini 2.5 Pro
============================================
This script programmatically generates a comprehensive context file containing:
1. Annotated file tree mapping to architecture components
2. All relevant source code (excluding packages, cache, etc.)
3. Intelligent annotations to help AI understand progress and architecture mapping

Author: Generated by Cursor AI for SD1 Project
Date: October 28, 2025
"""

import os
from pathlib import Path
from datetime import datetime
from typing import List, Set, Dict

# Project root directory
PROJECT_ROOT = Path(__file__).parent

# Files and directories to exclude
EXCLUDE_DIRS = {
    '__pycache__',
    '.pytest_cache',
    '.git',
    '.venv',
    'venv',
    'node_modules',
    '.idea',
    '.vscode',
    'dist',
    'build',
    '*.egg-info',
}

EXCLUDE_FILES = {
    '.DS_Store',
    '.gitignore',
    '*.pyc',
    '*.pyo',
    '*.pyd',
    '.Python',
}

# File extensions to include (relevant code files)
INCLUDE_EXTENSIONS = {
    '.py',
    '.md',
    '.txt',
    '.yml',
    '.yaml',
    '.json',
    '.conf',
    '.toml',
    '.ini',
    '.sh',
}

# Architecture component mappings for annotations
COMPONENT_MAPPINGS = {
    'schemas/': {
        'component': 'DATA CONTRACTS & MESSAGE SCHEMAS',
        'architecture_section': '3.2 (Data Stores) & 7.0 (Schema Alignment)',
        'status': 'IMPLEMENTED ‚úÖ',
        'description': 'Core Pydantic models for TaskMessage, ResultMessage, and all enums. Foundation for type-safe inter-component communication.',
        'owners': ['Jacobo Forero'],
    },
    'infrastructure/': {
        'component': 'TASK BROKER (MESSAGE BUS)',
        'architecture_section': '3.2 (Task Broker) & 5.0 (Queuing Subsystem)',
        'status': 'IMPLEMENTED ‚úÖ',
        'description': 'RabbitMQ configuration with priority queues, dead letter exchange (DLX), and DLQ for fault tolerance.',
        'owners': ['Team'],
    },
    'tests/schemas/': {
        'component': 'SCHEMA VALIDATION & TESTING',
        'architecture_section': '7.0 (Schema Alignment)',
        'status': 'IMPLEMENTED ‚úÖ',
        'description': '67 comprehensive tests ensuring schema integrity, validation, and serialization.',
        'owners': ['Jacobo Forero'],
    },
    'tests/infrastructure/': {
        'component': 'INFRASTRUCTURE INTEGRATION TESTING',
        'architecture_section': '5.0 (Queuing & Orchestration)',
        'status': 'IMPLEMENTED ‚úÖ',
        'description': 'End-to-end tests for RabbitMQ setup, message flow, DLQ functionality, and schema integration.',
        'owners': ['Team'],
    },
    'docs/': {
        'component': 'ARCHITECTURE & DESIGN DOCUMENTATION',
        'architecture_section': 'All sections',
        'status': 'COMPREHENSIVE ‚úÖ',
        'description': 'Detailed system architecture, agent specifications, and design principles.',
        'owners': ['Jacobo Forero', 'Team'],
    },
}

# Not yet implemented components (for context)
NOT_IMPLEMENTED = {
    'orchestrator/': {
        'component': 'ORCHESTRATOR',
        'architecture_section': '3.2 (Orchestrator)',
        'status': 'NOT IMPLEMENTED ‚ö†Ô∏è',
        'description': 'Central brain for DAG state management, task scheduling, and result processing.',
    },
    'agents/': {
        'component': 'AGENT POOL',
        'architecture_section': '3.2 (Worker Pools) & Agent Definitions',
        'status': 'NOT IMPLEMENTED ‚ö†Ô∏è',
        'description': 'LLM-based agents: Planner, Implementation, Testbench, Debug, Reflection, Specification Helper.',
    },
    'workers/': {
        'component': 'PROCESS & SIMULATION POOLS',
        'architecture_section': '3.2 (Worker Pools)',
        'status': 'NOT IMPLEMENTED ‚ö†Ô∏è',
        'description': 'Deterministic workers: Linter, Simulator, Synthesizer, Distillation.',
    },
    'design_context/': {
        'component': 'DESIGN CONTEXT STORAGE',
        'architecture_section': '3.2 (Data Stores)',
        'status': 'NOT IMPLEMENTED ‚ö†Ô∏è',
        'description': 'Read-only store for frozen specifications, DAG, and interfaces.',
    },
    'task_memory/': {
        'component': 'TASK MEMORY',
        'architecture_section': '3.2 (Data Stores)',
        'status': 'NOT IMPLEMENTED ‚ö†Ô∏è',
        'description': 'Per-task artifact storage: attempts, logs, distilled datasets, reflection outputs.',
    },
}


def should_exclude_path(path: Path) -> bool:
    """Check if a path should be excluded from the context."""
    # Check directory exclusions
    for part in path.parts:
        if part in EXCLUDE_DIRS or any(part.startswith(exc.rstrip('*')) for exc in EXCLUDE_DIRS if '*' in exc):
            return True
    
    # Check file exclusions
    if path.name in EXCLUDE_FILES:
        return True
    
    return False


def should_include_file(path: Path) -> bool:
    """Check if a file should be included based on extension."""
    return path.suffix in INCLUDE_EXTENSIONS


def generate_file_tree(root: Path, prefix: str = "", output: List[str] = None, indent_level: int = 0) -> List[str]:
    """Generate an annotated file tree structure."""
    if output is None:
        output = []
    
    try:
        items = sorted(root.iterdir(), key=lambda x: (not x.is_dir(), x.name))
    except PermissionError:
        return output
    
    for i, item in enumerate(items):
        if should_exclude_path(item):
            continue
        
        is_last = i == len(items) - 1
        connector = "‚îî‚îÄ‚îÄ " if is_last else "‚îú‚îÄ‚îÄ "
        
        relative_path = str(item.relative_to(PROJECT_ROOT)) + ('/' if item.is_dir() else '')
        
        # Add architecture annotation for key directories
        annotation = ""
        for path_pattern, info in COMPONENT_MAPPINGS.items():
            if relative_path.startswith(path_pattern):
                annotation = f"  # [{info['status']}] {info['component']}"
                break
        
        output.append(f"{prefix}{connector}{item.name}{annotation}")
        
        if item.is_dir():
            extension = "    " if is_last else "‚îÇ   "
            generate_file_tree(item, prefix + extension, output, indent_level + 1)
    
    return output


def get_relevant_files(root: Path) -> List[Path]:
    """Get all relevant files to include in the context."""
    relevant_files = []
    
    for path in root.rglob('*'):
        if path.is_file() and should_include_file(path) and not should_exclude_path(path):
            relevant_files.append(path)
    
    return sorted(relevant_files)


def generate_component_status() -> str:
    """Generate a component implementation status summary."""
    output = []
    output.append("=" * 80)
    output.append("COMPONENT IMPLEMENTATION STATUS")
    output.append("=" * 80)
    output.append("")
    
    output.append("IMPLEMENTED COMPONENTS:")
    output.append("-" * 80)
    for path, info in COMPONENT_MAPPINGS.items():
        output.append(f"\nüì¶ {info['component']}")
        output.append(f"   Path: {path}")
        output.append(f"   Status: {info['status']}")
        output.append(f"   Architecture: Section {info['architecture_section']}")
        output.append(f"   Description: {info['description']}")
        output.append(f"   Owners: {', '.join(info['owners'])}")
    
    output.append("\n\n" + "=" * 80)
    output.append("NOT YET IMPLEMENTED (Future Work):")
    output.append("-" * 80)
    for path, info in NOT_IMPLEMENTED.items():
        output.append(f"\n‚ö†Ô∏è  {info['component']}")
        output.append(f"   Planned Path: {path}")
        output.append(f"   Status: {info['status']}")
        output.append(f"   Architecture: Section {info['architecture_section']}")
        output.append(f"   Description: {info['description']}")
    
    output.append("\n" + "=" * 80)
    return "\n".join(output)


def generate_context_file():
    """Main function to generate the complete context file."""
    output = []
    
    # Header
    output.append("=" * 80)
    output.append("MULTI-AGENT HARDWARE DESIGN SYSTEM - CODEBASE CONTEXT")
    output.append("=" * 80)
    output.append(f"Generated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    output.append(f"Project: SD1 2025 Group 5 - Senior Design Capstone")
    output.append(f"Team: Jacobo Forero, Dexter Pressley, Mateus Verffel Mayer,")
    output.append(f"      Caleb Elliott, Andrew Chambers, Sammy Fares")
    output.append("=" * 80)
    output.append("")
    output.append("")
    
    # Project Overview
    output.append("PROJECT OVERVIEW")
    output.append("=" * 80)
    output.append("This is a multi-agent system designed to accelerate the digital hardware")
    output.append("design lifecycle. The system automates HDL generation, verification, and")
    output.append("integration through a two-phase approach:")
    output.append("")
    output.append("PHASE 1: Planning & Decomposition (Human-supervised)")
    output.append("  - Specification convergence with Specification Helper Agent")
    output.append("  - Automated DAG generation by Planner Agent")
    output.append("  - Frozen design context as immutable source of truth")
    output.append("")
    output.append("PHASE 2: Asynchronous Execution (Automated)")
    output.append("  - Parallel task execution across specialized agent/worker pools")
    output.append("  - State-driven progression: Stub ‚Üí Draft ‚Üí Testing ‚Üí Passing ‚Üí Frozen")
    output.append("  - Fault-tolerant queuing with Dead Letter Queue (DLQ)")
    output.append("")
    output.append("KEY ARCHITECTURAL PRINCIPLE:")
    output.append("  \"Exhaustive upfront planning enables mechanical, parallel execution\"")
    output.append("")
    output.append("")
    
    # Component Status
    output.append(generate_component_status())
    output.append("")
    output.append("")
    
    # File Tree
    output.append("=" * 80)
    output.append("ANNOTATED FILE TREE")
    output.append("=" * 80)
    output.append("Legend:")
    output.append("  [IMPLEMENTED ‚úÖ] - Fully implemented and tested")
    output.append("  [COMPREHENSIVE ‚úÖ] - Complete documentation")
    output.append("  [NOT IMPLEMENTED ‚ö†Ô∏è] - Planned but not yet built")
    output.append("")
    output.append(PROJECT_ROOT.name + "/")
    tree_lines = generate_file_tree(PROJECT_ROOT)
    output.extend(tree_lines)
    output.append("")
    output.append("")
    
    # File Contents
    output.append("=" * 80)
    output.append("COMPLETE SOURCE CODE")
    output.append("=" * 80)
    output.append("All relevant files are included below with clear delimiters.")
    output.append("Files are ordered logically: docs ‚Üí schemas ‚Üí infrastructure ‚Üí tests")
    output.append("")
    output.append("")
    
    relevant_files = get_relevant_files(PROJECT_ROOT)
    
    # Group files by category for better organization
    file_groups: Dict[str, List[Path]] = {
        'Documentation': [],
        'Schemas': [],
        'Infrastructure': [],
        'Tests - Schemas': [],
        'Tests - Infrastructure': [],
        'Project Configuration': [],
        'Other': [],
    }
    
    for file_path in relevant_files:
        relative = str(file_path.relative_to(PROJECT_ROOT))
        if relative.startswith('docs/'):
            file_groups['Documentation'].append(file_path)
        elif relative.startswith('schemas/') and not relative.startswith('schemas/__pycache__'):
            file_groups['Schemas'].append(file_path)
        elif relative.startswith('infrastructure/'):
            file_groups['Infrastructure'].append(file_path)
        elif relative.startswith('tests/schemas/'):
            file_groups['Tests - Schemas'].append(file_path)
        elif relative.startswith('tests/infrastructure/'):
            file_groups['Tests - Infrastructure'].append(file_path)
        elif file_path.name in ['pyproject.toml', 'pytest.ini', 'README.md']:
            file_groups['Project Configuration'].append(file_path)
        else:
            file_groups['Other'].append(file_path)
    
    # Output files by group
    for group_name, files in file_groups.items():
        if not files:
            continue
        
        output.append("=" * 80)
        output.append(f"CATEGORY: {group_name}")
        output.append("=" * 80)
        output.append("")
        
        for file_path in sorted(files):
            relative_path = file_path.relative_to(PROJECT_ROOT)
            output.append("-" * 80)
            output.append(f"FILE: {relative_path}")
            output.append("-" * 80)
            
            # Add component annotation
            for path_pattern, info in COMPONENT_MAPPINGS.items():
                if str(relative_path).startswith(path_pattern):
                    output.append(f"Component: {info['component']}")
                    output.append(f"Status: {info['status']}")
                    output.append(f"Architecture Reference: Section {info['architecture_section']}")
                    output.append("-" * 80)
                    break
            
            try:
                with open(file_path, 'r', encoding='utf-8') as f:
                    content = f.read()
                    output.append(content)
            except Exception as e:
                output.append(f"[ERROR: Could not read file: {e}]")
            
            output.append("")
            output.append("")
    
    # Footer
    output.append("=" * 80)
    output.append("END OF CODEBASE CONTEXT")
    output.append("=" * 80)
    output.append("")
    output.append("This context includes:")
    output.append("  - Complete architecture documentation")
    output.append("  - All implemented schemas and contracts")
    output.append("  - Infrastructure configuration (RabbitMQ with DLQ)")
    output.append("  - Comprehensive test suites (67+ schema tests, infrastructure tests)")
    output.append("  - Project configuration and setup instructions")
    output.append("")
    output.append("The codebase demonstrates:")
    output.append("  ‚úÖ Well-defined message contracts using Pydantic")
    output.append("  ‚úÖ Fault-tolerant message queuing with priority support")
    output.append("  ‚úÖ Comprehensive testing infrastructure")
    output.append("  ‚úÖ Clear architectural documentation")
    output.append("  ‚ö†Ô∏è  Agents and workers are planned but not yet implemented")
    output.append("  ‚ö†Ô∏è  Orchestrator and data stores are architectural designs only")
    output.append("")
    
    return "\n".join(output)


if __name__ == "__main__":
    print("Generating codebase context for Gemini 2.5 Pro...")
    print(f"Project root: {PROJECT_ROOT}")
    
    context = generate_context_file()
    
    output_file = PROJECT_ROOT / "CODEBASE_CONTEXT_FOR_GEMINI.txt"
    with open(output_file, 'w', encoding='utf-8') as f:
        f.write(context)
    
    file_size_kb = output_file.stat().st_size / 1024
    print(f"\n‚úÖ Context file generated successfully!")
    print(f"   Output: {output_file}")
    print(f"   Size: {file_size_kb:.1f} KB")
    print(f"\nYou can now upload this file to Google AI Studio for Gemini 2.5 Pro.")

